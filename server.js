require('dotenv').config();
const express = require('express');
const multer = require('multer');
const ytdl = require('@distube/ytdl-core');
const ffmpeg = require('fluent-ffmpeg');
const OpenAI = require('openai');
const cors = require('cors');
const fs = require('fs');
const path = require('path');
const { YoutubeTranscript } = require('youtube-transcript-api');

const app = express();
const PORT = process.env.PORT || 3000;

app.use(cors());
app.use(express.json());
app.use(express.static('public'));

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

const upload = multer({ dest: 'uploads/' });

if (!fs.existsSync('uploads')) {
  fs.mkdirSync('uploads');
}
if (!fs.existsSync('transcripts')) {
  fs.mkdirSync('transcripts');
}
if (!fs.existsSync('history')) {
  fs.mkdirSync('history');
}

let currentTranscript = '';
let currentMetadata = null;
let currentSummary = null;
let sessionCosts = {
  whisper: 0,
  gpt: 0,
  total: 0
};

// æ–™é‡‘è¨­å®šï¼ˆ2024å¹´6æœˆæ™‚ç‚¹ã®ä¾¡æ ¼ï¼‰
const pricing = {
  whisper: 0.006, // $0.006 per minute
  models: {
    'gpt-4o-mini': {
      input: 0.15 / 1000000, // $0.15 per 1M tokens
      output: 0.60 / 1000000  // $0.60 per 1M tokens
    },
    'gpt-4o': {
      input: 5.00 / 1000000, // $5.00 per 1M tokens
      output: 15.00 / 1000000  // $15.00 per 1M tokens
    },
    'gpt-4-turbo': {
      input: 10.00 / 1000000, // $10.00 per 1M tokens
      output: 30.00 / 1000000  // $30.00 per 1M tokens
    },
    'gpt-3.5-turbo': {
      input: 0.50 / 1000000, // $0.50 per 1M tokens
      output: 1.50 / 1000000  // $1.50 per 1M tokens
    }
  }
};

// å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
const historyFile = path.join('history', 'transcripts.json');

function loadHistory() {
  if (fs.existsSync(historyFile)) {
    try {
      return JSON.parse(fs.readFileSync(historyFile, 'utf8'));
    } catch (error) {
      console.error('Error loading history:', error);
      return [];
    }
  }
  return [];
}

function saveHistory(history) {
  try {
    fs.writeFileSync(historyFile, JSON.stringify(history, null, 2));
  } catch (error) {
    console.error('Error saving history:', error);
  }
}

function addToHistory(videoId, title, url, transcript, method, cost = 0, metadata = null, summary = null, language = 'original', gptModel = 'gpt-4o-mini') {
  const history = loadHistory();
  const entry = {
    id: videoId,
    title,
    url,
    transcript,
    method, // 'subtitle', 'whisper'
    language, // 'original', 'ja', 'en'
    gptModel, // GPTãƒ¢ãƒ‡ãƒ«æƒ…å ±
    cost,
    metadata,
    summary,
    timestamp: new Date().toISOString()
  };
  
  // æ—¢å­˜ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒã‚ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°è¿½åŠ 
  const existingIndex = history.findIndex(item => item.id === videoId);
  if (existingIndex >= 0) {
    history[existingIndex] = entry;
  } else {
    history.unshift(entry);
  }
  
  // æœ€æ–°100ä»¶ã¾ã§ä¿æŒ
  if (history.length > 100) {
    history.splice(100);
  }
  
  saveHistory(history);
  return entry;
}

// YouTubeãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†ææ©Ÿèƒ½
async function getYouTubeMetadata(url) {
  try {
    const info = await ytdl.getInfo(url);
    const videoDetails = info.videoDetails;
    const formats = info.formats;
    
    // ãƒãƒ£ãƒ—ã‚¿ãƒ¼æƒ…å ±ã®æŠ½å‡º
    const description = videoDetails.description || '';
    const chapterRegex = /(\d{1,2}:\d{2}(?::\d{2})?)\s+(.+)/gm;
    const chapters = [];
    let match;
    
    while ((match = chapterRegex.exec(description)) !== null) {
      chapters.push({
        timestamp: match[1],
        title: match[2].trim()
      });
    }
    
    // å­—å¹•æƒ…å ±
    const captions = info.player_response?.captions?.playerCaptionsTracklistRenderer?.captionTracks || [];
    
    return {
      basic: {
        title: videoDetails.title,
        videoId: videoDetails.videoId,
        duration: parseInt(videoDetails.lengthSeconds),
        channel: videoDetails.author.name,
        viewCount: parseInt(videoDetails.viewCount || 0),
        likes: parseInt(videoDetails.likes || 0),
        uploadDate: videoDetails.uploadDate,
        publishDate: videoDetails.publishDate,
        category: videoDetails.category,
        description: videoDetails.description
      },
      chapters: chapters,
      captions: captions.map(cap => ({
        language: cap.languageCode,
        name: cap.name.simpleText
      })),
      stats: {
        formatCount: formats.length,
        hasSubtitles: captions.length > 0,
        keywords: videoDetails.keywords || []
      }
    };
  } catch (error) {
    console.error('ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼:', error);
    return null;
  }
}

// æ–‡å­—èµ·ã“ã—çµæœã®æ•´å½¢
function formatTranscript(transcript) {
  if (!transcript) return '';
  
  // ã‚ˆã‚Šè©³ç´°ãªæ•´å½¢å‡¦ç†
  let formatted = transcript
    // é€£ç¶šã™ã‚‹ç©ºç™½ã‚’å˜ä¸€ã®ç©ºç™½ã«
    .replace(/\s+/g, ' ')
    .trim();
  
  // æ—¥æœ¬èªã®å¥èª­ç‚¹ã§æ”¹è¡Œ
  formatted = formatted
    .replace(/([ã€‚ï¼ï¼Ÿ])/g, '$1\n\n')
    .replace(/([ã€])/g, '$1 ');
  
  // è‹±èªã®æ–‡æœ«ã§æ”¹è¡Œ
  formatted = formatted
    .replace(/([.!?])\s+([A-Z])/g, '$1\n\n$2');
  
  // é•·ã„æ–‡ã‚’é©åº¦ã«åˆ†å‰²ï¼ˆ100æ–‡å­—ç¨‹åº¦ï¼‰
  formatted = formatted
    .replace(/(.{100,}?)([ã€‚ï¼ï¼Ÿã€,.])/g, '$1$2\n');
  
  // ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§æ”¹è¡Œã‚’è¿½åŠ 
  formatted = formatted
    // ã€Œã§ã™ã€ã€Œã¾ã™ã€ã€Œã ã€ã€Œã§ã‚ã‚‹ã€ã®å¾Œã«æ”¹è¡Œ
    .replace(/(ã§ã™|ã¾ã™|ã |ã§ã‚ã‚‹)([ã€‚]?)\s*([ã‚-ã‚“])/g, '$1$2\n\n$3')
    // ã€Œãã—ã¦ã€ã€Œã—ã‹ã—ã€ã€Œã¨ã“ã‚ã§ã€ã€Œã¾ãŸã€ãªã©ã®æ¥ç¶šè©ã®å‰ã«æ”¹è¡Œ
    .replace(/([ã€‚])\s*(ãã—ã¦|ã—ã‹ã—|ã¨ã“ã‚ã§|ã¾ãŸ|ã•ã‚‰ã«|ä¸€æ–¹|ã¤ã¾ã‚Š|ãªãŠ|ã¡ãªã¿ã«)/g, '$1\n\n$2')
    // è³ªå•æ–‡ã®å¾Œã«æ”¹è¡Œ
    .replace(/([ï¼Ÿ])\s*([ã‚-ã‚“ã‚¢-ãƒ³])/g, '$1\n\n$2');
  
  // è¤‡æ•°ã®æ”¹è¡Œã‚’çµ±ä¸€
  formatted = formatted
    .replace(/\n{3,}/g, '\n\n')
    .replace(/\n\s+\n/g, '\n\n');
  
  // è¡Œé ­ã®ç©ºç™½ã‚’å‰Šé™¤
  formatted = formatted
    .split('\n')
    .map(line => line.trim())
    .join('\n');
  
  // ç©ºè¡Œã‚’å‰Šé™¤ã—ã¤ã¤ã€æ®µè½é–“ã®ç©ºè¡Œã¯ä¿æŒ
  formatted = formatted
    .replace(/\n\n+/g, '\n\n')
    .trim();
  
  return formatted;
}

// è¦ç´„ç”Ÿæˆæ©Ÿèƒ½
async function generateSummary(transcript, metadata, gptModel = 'gpt-4o-mini') {
  try {
    const systemMessage = `ã‚ãªãŸã¯å‹•ç”»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®åˆ†æå°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—ã‚’åˆ†æã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

å‹•ç”»æƒ…å ±:
- ã‚¿ã‚¤ãƒˆãƒ«: ${metadata?.basic?.title || 'ä¸æ˜'}
- é•·ã•: ${metadata?.basic?.duration ? Math.floor(metadata.basic.duration/60) + 'åˆ†' + (metadata.basic.duration%60) + 'ç§’' : 'ä¸æ˜'}
- ãƒãƒ£ãƒ³ãƒãƒ«: ${metadata?.basic?.channel || 'ä¸æ˜'}

è¦ç´„ã¯ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:

## ğŸ“ å…¨ä½“è¦ç´„
[å‹•ç”»å…¨ä½“ã®æ¦‚è¦ã‚’2-3æ–‡ã§]

## ğŸ¯ ä¸»è¦ãƒã‚¤ãƒ³ãƒˆ
[æœ€ã‚‚é‡è¦ãª3-5ã¤ã®ãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã§]

## ğŸ“Š ãƒˆãƒ”ãƒƒã‚¯åˆ¥è©³ç´°
[å†…å®¹ã‚’3-5ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã«åˆ†ã‘ã¦ã€ãã‚Œãã‚Œè©³ç´°ã«è¦ç´„]

### ğŸ” ãƒˆãƒ”ãƒƒã‚¯1: [ã‚¿ã‚¤ãƒˆãƒ«]
[ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã®è©³ç´°å†…å®¹ - æ·±æ˜ã‚Šè³ªå•ãŒã§ãã‚‹ç¨‹åº¦ã®è©³ã—ã•ã§]

### ğŸ” ãƒˆãƒ”ãƒƒã‚¯2: [ã‚¿ã‚¤ãƒˆãƒ«]
[ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã®è©³ç´°å†…å®¹]

(ä»¥ä¸‹ã€å¿…è¦ã«å¿œã˜ã¦ç¶šã‘ã‚‹)

## ğŸ’¡ ãŠã™ã™ã‚æ·±æ˜ã‚Šè³ªå•
[è¦–è´è€…ãŒè³ªå•ã—ãŸããªã‚Šãã†ãªå…·ä½“çš„ãªè³ªå•ä¾‹ã‚’3-5å€‹]

æ–‡å­—èµ·ã“ã—å†…å®¹:
${transcript}`;

    const maxTokens = gptModel === 'gpt-3.5-turbo' ? 1500 : 2000;

    const response = await openai.chat.completions.create({
      model: gptModel,
      messages: [
        {
          role: 'system',
          content: systemMessage
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.3
    });

    const inputTokens = Math.ceil(systemMessage.length / 4);
    const outputTokens = Math.ceil(response.choices[0].message.content.length / 4);
    const modelPricing = pricing.models[gptModel];
    const summaryCost = (inputTokens * modelPricing.input) + (outputTokens * modelPricing.output);
    
    sessionCosts.gpt += summaryCost;
    sessionCosts.total += summaryCost;

    return {
      content: response.choices[0].message.content,
      model: gptModel,
      cost: summaryCost,
      tokens: { input: inputTokens, output: outputTokens }
    };

  } catch (error) {
    console.error('è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼:', error);
    return null;
  }
}

async function downloadYouTubeAudio(url, outputPath) {
  return new Promise((resolve, reject) => {
    const stream = ytdl(url, { quality: 'highestaudio' });
    
    ffmpeg(stream)
      .audioCodec('libmp3lame')
      .audioBitrate(64)
      .audioChannels(1)
      .audioFrequency(16000)
      .toFormat('mp3')
      .on('error', (err) => {
        console.error('FFmpeg error:', err);
        reject(err);
      })
      .on('end', () => {
        console.log('Audio extraction completed');
        resolve();
      })
      .save(outputPath);
  });
}

async function transcribeAudio(audioPath, language = 'original') {
  const stats = fs.statSync(audioPath);
  const fileSizeInBytes = stats.size;
  const maxSize = 25 * 1024 * 1024; // 25MB
  
  if (fileSizeInBytes > maxSize) {
    // ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã‚‹å ´åˆã¯åˆ†å‰²å‡¦ç†
    return await transcribeLargeAudio(audioPath, language);
  }
  
  const audioFile = fs.createReadStream(audioPath);
  
  const transcriptionParams = {
    file: audioFile,
    model: 'whisper-1'
  };
  
  // è¨€èªè¨­å®šã‚’è¿½åŠ 
  if (language !== 'original') {
    transcriptionParams.language = language;
  }
  
  const transcription = await openai.audio.transcriptions.create(transcriptionParams);
  
  return transcription.text;
}

async function transcribeLargeAudio(audioPath, language = 'original') {
  const segmentDuration = 600; // 10åˆ†ã”ã¨ã«åˆ†å‰²
  const segmentPaths = [];
  let segmentIndex = 0;
  
  return new Promise((resolve, reject) => {
    // ã¾ãšéŸ³å£°ã®é•·ã•ã‚’å–å¾—
    ffmpeg.ffprobe(audioPath, async (err, metadata) => {
      if (err) {
        reject(err);
        return;
      }
      
      const duration = metadata.format.duration;
      const segments = Math.ceil(duration / segmentDuration);
      const transcripts = [];
      
      try {
        // å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†
        for (let i = 0; i < segments; i++) {
          const startTime = i * segmentDuration;
          const segmentPath = audioPath.replace('.mp3', `_segment_${i}.mp3`);
          segmentPaths.push(segmentPath);
          
          await new Promise((segResolve, segReject) => {
            ffmpeg(audioPath)
              .seekInput(startTime)
              .duration(segmentDuration)
              .on('error', segReject)
              .on('end', segResolve)
              .save(segmentPath);
          });
          
          // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ–‡å­—èµ·ã“ã—
          const audioFile = fs.createReadStream(segmentPath);
          
          const transcriptionParams = {
            file: audioFile,
            model: 'whisper-1'
          };
          
          // è¨€èªè¨­å®šã‚’è¿½åŠ 
          if (language !== 'original') {
            transcriptionParams.language = language;
          }
          
          const transcription = await openai.audio.transcriptions.create(transcriptionParams);
          
          transcripts.push(transcription.text);
        }
        
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        segmentPaths.forEach(path => {
          if (fs.existsSync(path)) {
            fs.unlinkSync(path);
          }
        });
        
        resolve(transcripts.join(' '));
        
      } catch (error) {
        // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        segmentPaths.forEach(path => {
          if (fs.existsSync(path)) {
            fs.unlinkSync(path);
          }
        });
        reject(error);
      }
    });
  });
}

async function getYouTubeSubtitles(videoId, preferredLanguage = 'original') {
  const languageOrder = getLanguageOrder(preferredLanguage);
  
  for (const lang of languageOrder) {
    try {
      console.log(`Trying to get ${lang} subtitles...`);
      const transcripts = await YoutubeTranscript.fetchTranscript(videoId, {
        lang: lang
      });
      
      if (transcripts && transcripts.length > 0) {
        console.log(`Found ${lang} subtitles`);
        return {
          text: transcripts.map(item => item.text).join(' '),
          detectedLanguage: lang
        };
      }
    } catch (error) {
      console.log(`No ${lang} subtitles found`);
      continue;
    }
  }
  
  console.log('No subtitles available in any language');
  return null;
}

function getLanguageOrder(preferredLanguage) {
  switch (preferredLanguage) {
    case 'ja':
      return ['ja', 'en'];
    case 'en':
      return ['en', 'ja'];
    case 'original':
    default:
      // originalã®å ´åˆã¯åˆ©ç”¨å¯èƒ½ãªå­—å¹•ã‚’å„ªå…ˆé †ä½ã§è©¦è¡Œ
      return ['ja', 'en', 'ko', 'zh', 'es', 'fr', 'de', 'it', 'pt', 'ru'];
  }
}

function extractVideoId(url) {
  const regex = /(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)/;
  const match = url.match(regex);
  return match ? match[1] : null;
}

function calculateAudioDuration(audioPath) {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(audioPath, (err, metadata) => {
      if (err) {
        reject(err);
      } else {
        resolve(metadata.format.duration);
      }
    });
  });
}

app.post('/upload-youtube', async (req, res) => {
  try {
    const { url, language = 'original', gptModel = 'gpt-4o-mini' } = req.body;
    
    if (!url) {
      return res.status(400).json({ error: 'YouTube URL is required' });
    }

    if (!ytdl.validateURL(url)) {
      return res.status(400).json({ error: 'Invalid YouTube URL' });
    }

    const videoId = extractVideoId(url);
    if (!videoId) {
      return res.status(400).json({ error: 'Could not extract video ID from URL' });
    }

    // å±¥æ­´ã‹ã‚‰æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜è¨€èªãƒ»ãƒ¢ãƒ‡ãƒ«è¨­å®šã®ã‚‚ã®ï¼‰
    const history = loadHistory();
    const existingEntry = history.find(item => 
      item.id === videoId && 
      item.language === language && 
      item.gptModel === gptModel
    );
    if (existingEntry) {
      currentTranscript = existingEntry.transcript;
      currentMetadata = existingEntry.metadata;
      currentSummary = existingEntry.summary;
      return res.json({
        success: true,
        title: existingEntry.title,
        transcript: existingEntry.transcript,
        summary: existingEntry.summary?.content,
        metadata: existingEntry.metadata,
        method: existingEntry.method,
        language: existingEntry.language,
        gptModel: existingEntry.gptModel,
        message: 'Retrieved from history',
        fromHistory: true,
        costs: sessionCosts
      });
    }

    const videoInfo = await ytdl.getInfo(url);
    const videoTitle = videoInfo.videoDetails.title;

    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    console.log('Getting video metadata...');
    const metadata = await getYouTubeMetadata(url);
    currentMetadata = metadata;

    // ã¾ãšYouTubeã®å­—å¹•ã‚’è©¦ã™
    console.log(`Checking for YouTube subtitles (preferred language: ${language})...`);
    const subtitlesResult = await getYouTubeSubtitles(videoId, language);
    
    let transcript;
    let method;
    let cost = 0;
    let detectedLanguage = language;

    if (subtitlesResult) {
      console.log(`Using YouTube subtitles (${subtitlesResult.detectedLanguage})`);
      transcript = subtitlesResult.text;
      method = 'subtitle';
      detectedLanguage = subtitlesResult.detectedLanguage;
    } else {
      console.log('No subtitles found, using Whisper transcription...');
      const audioPath = path.join('uploads', `${Date.now()}_audio.mp3`);

      await downloadYouTubeAudio(url, audioPath);
      
      // éŸ³å£°ã®é•·ã•ã‚’è¨ˆç®—ã—ã¦ã‚³ã‚¹ãƒˆã‚’ç®—å‡º
      const duration = await calculateAudioDuration(audioPath);
      const durationMinutes = Math.ceil(duration / 60);
      cost = durationMinutes * pricing.whisper;
      sessionCosts.whisper += cost;
      sessionCosts.total += cost;

      transcript = await transcribeAudio(audioPath, language);
      method = 'whisper';

      fs.unlinkSync(audioPath);
    }

    // æ–‡å­—èµ·ã“ã—çµæœã‚’æ•´å½¢
    const formattedTranscript = formatTranscript(transcript);
    currentTranscript = formattedTranscript;

    // è¦ç´„ã‚’ç”Ÿæˆ
    console.log(`Generating summary using ${gptModel}...`);
    const summary = await generateSummary(formattedTranscript, metadata, gptModel);
    currentSummary = summary;

    // å±¥æ­´ã«ä¿å­˜
    addToHistory(videoId, videoTitle, url, formattedTranscript, method, cost, metadata, summary, language, gptModel);

    // ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚ä¿å­˜
    const transcriptPath = path.join('transcripts', `${Date.now()}_${videoId}_${language}_${gptModel}_transcript.txt`);
    fs.writeFileSync(transcriptPath, formattedTranscript);

    res.json({
      success: true,
      title: videoTitle,
      transcript: formattedTranscript,
      summary: summary?.content,
      metadata: metadata,
      method: method,
      language: language,
      gptModel: gptModel,
      detectedLanguage: detectedLanguage,
      cost: cost,
      message: `Video transcribed successfully using ${method} (${detectedLanguage})`,
      costs: sessionCosts
    });

  } catch (error) {
    console.error('Error processing YouTube video:', error);
    res.status(500).json({ error: 'Failed to process YouTube video' });
  }
});

app.post('/chat', async (req, res) => {
  try {
    const { message, gptModel = 'gpt-4o-mini' } = req.body;
    
    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    if (!currentTranscript) {
      return res.status(400).json({ error: 'No transcript available. Please upload a YouTube video first.' });
    }

    // ã‚ˆã‚Šè©³ç´°ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æä¾›
    let contextInfo = `ä»¥ä¸‹ã¯YouTubeå‹•ç”»ã®æ–‡å­—èµ·ã“ã—ã§ã™ã€‚ã“ã®å†…å®¹ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n\n`;
    
    if (currentMetadata) {
      contextInfo += `å‹•ç”»æƒ…å ±:\n`;
      contextInfo += `- ã‚¿ã‚¤ãƒˆãƒ«: ${currentMetadata.basic.title}\n`;
      contextInfo += `- ãƒãƒ£ãƒ³ãƒãƒ«: ${currentMetadata.basic.channel}\n`;
      contextInfo += `- é•·ã•: ${Math.floor(currentMetadata.basic.duration/60)}åˆ†${currentMetadata.basic.duration%60}ç§’\n`;
      if (currentMetadata.chapters.length > 0) {
        contextInfo += `- ãƒãƒ£ãƒ—ã‚¿ãƒ¼: ${currentMetadata.chapters.map(c => `${c.timestamp} ${c.title}`).join(', ')}\n`;
      }
      contextInfo += `\n`;
    }
    
    if (currentSummary) {
      contextInfo += `å‹•ç”»è¦ç´„:\n${currentSummary.content}\n\n`;
    }
    
    contextInfo += `æ–‡å­—èµ·ã“ã—å†…å®¹:\n${currentTranscript}`;
    
    const inputTokens = Math.ceil((contextInfo.length + message.length) / 4); // æ¦‚ç®—
    
    const maxTokens = gptModel === 'gpt-3.5-turbo' ? 1000 : 1500;
    
    const response = await openai.chat.completions.create({
      model: gptModel,
      messages: [
        {
          role: 'system',
          content: contextInfo
        },
        {
          role: 'user',
          content: message
        }
      ],
      max_tokens: maxTokens,
      temperature: 0.7
    });

    const outputTokens = Math.ceil((response.choices[0].message.content.length) / 4); // æ¦‚ç®—
    const modelPricing = pricing.models[gptModel];
    const chatCost = (inputTokens * modelPricing.input) + (outputTokens * modelPricing.output);
    
    sessionCosts.gpt += chatCost;
    sessionCosts.total += chatCost;

    res.json({
      success: true,
      response: response.choices[0].message.content,
      model: gptModel,
      cost: chatCost,
      costs: sessionCosts,
      tokens: {
        input: inputTokens,
        output: outputTokens
      }
    });

  } catch (error) {
    console.error('Error in chat:', error);
    res.status(500).json({ error: 'Failed to process chat message' });
  }
});

app.get('/transcript', (req, res) => {
  res.json({
    transcript: currentTranscript || 'No transcript available'
  });
});

app.get('/history', (req, res) => {
  const history = loadHistory();
  res.json({
    success: true,
    history: history
  });
});

app.get('/costs', (req, res) => {
  res.json({
    success: true,
    costs: sessionCosts
  });
});

app.post('/load-from-history', (req, res) => {
  try {
    const { videoId } = req.body;
    
    if (!videoId) {
      return res.status(400).json({ error: 'Video ID is required' });
    }

    const history = loadHistory();
    const entry = history.find(item => item.id === videoId);
    
    if (!entry) {
      return res.status(404).json({ error: 'Entry not found in history' });
    }

    currentTranscript = entry.transcript;
    currentMetadata = entry.metadata;
    currentSummary = entry.summary;
    
    res.json({
      success: true,
      title: entry.title,
      transcript: entry.transcript,
      summary: entry.summary?.content,
      metadata: entry.metadata,
      method: entry.method,
      cost: entry.cost,
      timestamp: entry.timestamp,
      message: 'Loaded from history'
    });

  } catch (error) {
    console.error('Error loading from history:', error);
    res.status(500).json({ error: 'Failed to load from history' });
  }
});

// æ·±æ˜ã‚Šè³ªå•ææ¡ˆAPI
app.get('/suggested-questions', (req, res) => {
  try {
    if (!currentSummary || !currentMetadata) {
      return res.status(400).json({ error: 'No summary or metadata available' });
    }

    // è¦ç´„ã‹ã‚‰æ·±æ˜ã‚Šè³ªå•ã‚’æŠ½å‡º
    const summaryContent = currentSummary.content;
    const questionsMatch = summaryContent.match(/## ğŸ’¡ ãŠã™ã™ã‚æ·±æ˜ã‚Šè³ªå•\s*([\s\S]*?)(?=##|$)/);
    
    let suggestedQuestions = [];
    if (questionsMatch) {
      const questionsText = questionsMatch[1];
      suggestedQuestions = questionsText
        .split('\n')
        .filter(line => line.trim().startsWith('-') || line.trim().match(/^\d+\./))
        .map(line => line.replace(/^[-\d.]\s*/, '').trim())
        .filter(q => q.length > 0);
    }

    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è¿½åŠ è³ªå•
    const metadataQuestions = [];
    if (currentMetadata.chapters.length > 0) {
      metadataQuestions.push(`ã€Œ${currentMetadata.chapters[0].title}ã€ã®éƒ¨åˆ†ã«ã¤ã„ã¦è©³ã—ãæ•™ãˆã¦`);
    }
    if (currentMetadata.basic.category) {
      metadataQuestions.push(`ã“ã®å‹•ç”»ã®${currentMetadata.basic.category}åˆ†é‡ã§ã®ä½ç½®ã¥ã‘ã¯ï¼Ÿ`);
    }

    res.json({
      success: true,
      questions: [...suggestedQuestions, ...metadataQuestions].slice(0, 8)
    });

  } catch (error) {
    console.error('Error getting suggested questions:', error);
    res.status(500).json({ error: 'Failed to get suggested questions' });
  }
});

// ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å–å¾—API
app.get('/metadata', (req, res) => {
  res.json({
    success: true,
    metadata: currentMetadata,
    summary: currentSummary?.content
  });
});

app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});