diff --git a/src/components/pages/AnalyzePage.tsx b/src/components/pages/AnalyzePage.tsx
index 05d1d56..0888f71 100644
--- a/src/components/pages/AnalyzePage.tsx
+++ b/src/components/pages/AnalyzePage.tsx
@@ -145,7 +145,8 @@ const AnalyzePage: React.FC = () => {
         },
         transcript: data.transcript,
         summary: data.summary,
-        timestampedSegments: data.timestampedSegments || []
+        timestampedSegments: data.timestampedSegments || [],
+        transcriptSource: data.method as 'subtitle' | 'whisper'
       }
       
       setCurrentVideo(videoMetadata)
@@ -548,6 +549,7 @@ const AnalyzePage: React.FC = () => {
               transcript={currentVideo.transcript}
               timestampedSegments={currentVideo.timestampedSegments}
               summary={currentVideo.summary}
+              transcriptSource={currentVideo.transcriptSource}
               onSeek={(time) => {
                 console.log('🎥 AnalyzePage: onSeek called with time:', time)
                 console.log('🎥 AnalyzePage: playerRef available:', !!playerRef)
diff --git a/src/components/shared/TranscriptViewer.tsx b/src/components/shared/TranscriptViewer.tsx
index 2c369df..041dbb0 100644
--- a/src/components/shared/TranscriptViewer.tsx
+++ b/src/components/shared/TranscriptViewer.tsx
@@ -9,6 +9,7 @@ interface TranscriptViewerProps {
     text: string
   }>
   summary?: string
+  transcriptSource?: 'subtitle' | 'whisper'
   onSeek?: (time: number) => void
   onQuestionClick?: (question: string) => void
 }
@@ -22,7 +23,7 @@ const formatTime = (seconds: number): string => {
   return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`
 }
 
-const TranscriptViewer: React.FC<TranscriptViewerProps> = ({ transcript, timestampedSegments, summary: initialSummary, onSeek, onQuestionClick }) => {
+const TranscriptViewer: React.FC<TranscriptViewerProps> = ({ transcript, timestampedSegments, summary: initialSummary, transcriptSource, onSeek, onQuestionClick }) => {
   const [activeTab, setActiveTab] = useState<TabType>('transcript')
   const [summary, setSummary] = useState(initialSummary || '')
   const [article, setArticle] = useState('')
@@ -130,7 +131,29 @@ const TranscriptViewer: React.FC<TranscriptViewerProps> = ({ transcript, timesta
         if (timestampedSegments && timestampedSegments.length > 0) {
           return (
             <div className="space-y-4">
-              <div className="flex justify-end mb-4">
+              <div className="flex justify-between items-center mb-4">
+                {/* Transcript source indicator */}
+                {transcriptSource && (
+                  <div className="flex items-center">
+                    <span className={`inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium ${
+                      transcriptSource === 'subtitle' 
+                        ? 'bg-green-100 text-green-800 border border-green-200' 
+                        : 'bg-blue-100 text-blue-800 border border-blue-200'
+                    }`}>
+                      {transcriptSource === 'subtitle' ? (
+                        <>
+                          <span className="mr-1">📺</span>
+                          YouTube キャプション
+                        </>
+                      ) : (
+                        <>
+                          <span className="mr-1">🤖</span>
+                          Whisper AI 生成
+                        </>
+                      )}
+                    </span>
+                  </div>
+                )}
                 <button
                   onClick={() => alert('文字起こしの再生成機能は実装予定です')}
                   className="btn-regenerate inline-flex items-center px-4 py-2 text-sm font-medium rounded-lg transition-colors"
@@ -163,7 +186,29 @@ const TranscriptViewer: React.FC<TranscriptViewerProps> = ({ transcript, timesta
         }
         return transcript ? (
           <div className="space-y-4">
-            <div className="flex justify-end mb-4">
+            <div className="flex justify-between items-center mb-4">
+              {/* Transcript source indicator */}
+              {transcriptSource && (
+                <div className="flex items-center">
+                  <span className={`inline-flex items-center px-2.5 py-0.5 rounded-full text-xs font-medium ${
+                    transcriptSource === 'subtitle' 
+                      ? 'bg-green-100 text-green-800 border border-green-200' 
+                      : 'bg-blue-100 text-blue-800 border border-blue-200'
+                  }`}>
+                    {transcriptSource === 'subtitle' ? (
+                      <>
+                        <span className="mr-1">📺</span>
+                        YouTube キャプション
+                      </>
+                    ) : (
+                      <>
+                        <span className="mr-1">🤖</span>
+                        Whisper AI 生成
+                      </>
+                    )}
+                  </span>
+                </div>
+              )}
               <button
                 onClick={() => alert('文字起こしの再生成機能は実装予定です')}
                 className="btn-regenerate inline-flex items-center px-4 py-2 text-sm font-medium rounded-lg transition-colors"
diff --git a/src/server.ts b/src/server.ts
index 1876203..cefb3f0 100644
--- a/src/server.ts
+++ b/src/server.ts
@@ -98,7 +98,7 @@ if (!fs.existsSync('history')) {
 
 let currentTranscript = '';
 let currentMetadata: VideoMetadata | null = null;
-let currentVideo: VideoMetadata | null = null;
+const currentVideo: VideoMetadata | null = null;
 // let currentSummary: Summary | null = null;
 let currentTimestampedSegments: TimestampedSegment[] = [];
 let currentArticle: string | null = null;
diff --git a/src/types/index.ts b/src/types/index.ts
index cd79c0c..778e7d8 100644
--- a/src/types/index.ts
+++ b/src/types/index.ts
@@ -22,6 +22,7 @@ export interface VideoMetadata {
   transcript?: string;
   summary?: string;
   timestampedSegments?: TimestampedSegment[];
+  transcriptSource?: 'subtitle' | 'whisper';
 }
 
 export interface Chapter {
